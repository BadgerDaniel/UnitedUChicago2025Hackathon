{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Fetching for Atlanta (Hartsfield‚ÄëJackson ATL) (DMA 524)...\n",
      "‚è≥ Sleeping 14s...\n",
      "\n",
      "üì° Fetching for Los Angeles (LAX) (DMA 803)...\n",
      "‚è≥ Sleeping 13s...\n",
      "\n",
      "üì° Fetching for Dallas‚ÄìFort Worth (DFW) (DMA 623)...\n",
      "‚è≥ Sleeping 13s...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# DMA list with airport & DMA code\n",
    "dma_targets = [\n",
    "    {\"dma_code\": 524, \"dma_name\": \"Atlanta (Hartsfield‚ÄëJackson ATL)\"},\n",
    "    {\"dma_code\": 803, \"dma_name\": \"Los Angeles (LAX)\"},\n",
    "    {\"dma_code\": 623, \"dma_name\": \"Dallas‚ÄìFort Worth (DFW)\"},\n",
    "    {\"dma_code\": 751, \"dma_name\": \"Denver (DEN)\"},\n",
    "    {\"dma_code\": 602, \"dma_name\": \"Chicago (O‚ÄôHare)\"},\n",
    "    {\"dma_code\": 534, \"dma_name\": \"Orlando (MCO)\"},\n",
    "    {\"dma_code\": 517, \"dma_name\": \"Charlotte (CLT)\"},\n",
    "    {\"dma_code\": 839, \"dma_name\": \"Las Vegas (LAS)\"},\n",
    "    {\"dma_code\": 819, \"dma_name\": \"Seattle (SEA)\"},\n",
    "    {\"dma_code\": 528, \"dma_name\": \"Miami (MIA)\"},\n",
    "    {\"dma_code\": 753, \"dma_name\": \"Phoenix (PHX)\"},\n",
    "    {\"dma_code\": 807, \"dma_name\": \"San Francisco (SFO)\"},\n",
    "    {\"dma_code\": 501, \"dma_name\": \"New York Metro (EWR/JFK/LGA)\"},\n",
    "    {\"dma_code\": 618, \"dma_name\": \"Houston (IAH)\"},\n",
    "    {\"dma_code\": 506, \"dma_name\": \"Boston (BOS)\"}\n",
    "]\n",
    "\n",
    "# Base URL\n",
    "base_url = \"https://trends.google.com/trending?geo={dma}&hours=24&sort=search-volume\"\n",
    "\n",
    "# Output list\n",
    "all_trends = []\n",
    "\n",
    "# Start scraping\n",
    "for target in dma_targets:\n",
    "    dma_code = target[\"dma_code\"]\n",
    "    dma_name = target[\"dma_name\"]\n",
    "    url = base_url.format(dma=dma_code)\n",
    "\n",
    "    print(f\"üì° Fetching for {dma_name} (DMA {dma_code})...\")\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Parse trending topics\n",
    "        trends = soup.find_all(\"div\", class_=\"title\")\n",
    "\n",
    "        for t in trends:\n",
    "            all_trends.append({\n",
    "                \"DMA Code\": dma_code,\n",
    "                \"DMA Name\": dma_name,\n",
    "                \"Trend\": t.get_text(strip=True)\n",
    "            })\n",
    "\n",
    "        # Healthy, generous delay\n",
    "        delay = 10 + (dma_code % 5)\n",
    "        print(f\"‚è≥ Sleeping {delay}s...\\n\")\n",
    "        time.sleep(delay)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to fetch {dma_name}: {e}\")\n",
    "        continue\n",
    "from datetime import datetime\n",
    "# Save to CSV\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "filename = f\"dma_trending_topics_{today}.csv\"\n",
    "pd.DataFrame(all_trends).to_csv(filename, index=False)\n",
    "print(f\"‚úÖ Done! Results saved to '{filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
